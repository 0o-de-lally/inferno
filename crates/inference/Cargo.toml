[package]
name = "inferno-inference"
version.workspace = true
edition.workspace = true
authors.workspace = true
license.workspace = true
repository.workspace = true
description = "Inference engine implementation for Inferno with Burn ML framework support"

[dependencies]
# Workspace dependencies
tokio = { workspace = true }
serde = { workspace = true }
serde_json = { workspace = true }
tracing = { workspace = true }
thiserror = { workspace = true }
async-trait = { workspace = true }
chrono = { workspace = true }

# Local dependencies
inferno-shared = { workspace = true }

# HTTP server

# Minimal dependencies for real CPU inference
rand = { version = "0.8", optional = true }

# HTTP client for model downloads
reqwest = { workspace = true, optional = true }

# FFI and build dependencies

# Configuration and environment
config = { workspace = true }
toml = { workspace = true }
num_cpus = { workspace = true }

# Async utilities

# Memory management
parking_lot = { workspace = true }
once_cell = { workspace = true }

# Performance monitoring

# JSON and validation
validator = { workspace = true }

# Burn ML Framework for real model inference
burn = { workspace = true, optional = true }
burn-core = { workspace = true, optional = true }
burn-ndarray = { workspace = true, optional = true }
burn-tensor = { workspace = true, optional = true }
tokenizers = { workspace = true, optional = true }
hf-hub = { workspace = true, optional = true }

# No build dependencies needed for pure Rust Burn framework implementation

[dev-dependencies]
tokio-test = { workspace = true }
criterion = { workspace = true }
proptest = { workspace = true }
serial_test = { workspace = true }
reqwest = { workspace = true }
tempfile = { workspace = true }
rstest = { workspace = true }

[features]
default = ["burn-cpu"]
burn-cpu = [
    "rand", 
    "reqwest",
    "burn/ndarray",
    "burn/autodiff", 
    "burn-core",
    "burn-ndarray",
    "burn-tensor",
    "tokenizers",
    "hf-hub/tokio"
]  # Real deterministic SmolLM3 model inference
burn-cuda = [
    "rand", 
    "reqwest",
    "burn",
    "burn-core",
    "burn-ndarray", 
    "burn-tensor",
    "tokenizers",
    "hf-hub"
]  # Same as CPU for now (future acceleration)
cuda = []  # Reserved for future use

# Benchmarks will be added in later phases
# [[bench]]
# name = "latency" 
# harness = false

# [[bench]]
# name = "throughput"
# harness = false