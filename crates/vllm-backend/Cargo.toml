[package]
name = "inferno-vllm-backend"
version.workspace = true
edition.workspace = true
authors.workspace = true
license.workspace = true
repository.workspace = true
description = "VLLM backend implementation for Inferno with CUDA acceleration"

[dependencies]
# Workspace dependencies
tokio = { workspace = true }
serde = { workspace = true }
serde_json = { workspace = true }
tracing = { workspace = true }
tracing-subscriber = { workspace = true }
thiserror = { workspace = true }
async-trait = { workspace = true }
bytes = { workspace = true }
chrono = { workspace = true }

# Local dependencies
inferno-shared = { path = "../shared" }

# HTTP server
axum = { version = "0.7", features = ["macros"] }
tower = { version = "0.4", features = ["full"] }
tower-http = { version = "0.5", features = ["cors", "trace", "request-id"] }
hyper = { workspace = true }
http = { workspace = true }

# GPU/CUDA dependencies  
cudarc = { version = "0.11", features = ["std", "cublas", "cudnn"], optional = true }
candle-core = { version = "0.6", features = ["cuda"], optional = true }
candle-nn = { version = "0.6", optional = true }
half = "2.3"

# FFI and build dependencies
libc = "0.2"
bindgen = { version = "0.69", optional = true }

# Configuration and environment
config = "0.14"
envy = "0.4"
toml = "0.8"
num_cpus = "1.16"

# Async utilities
futures = "0.3"
futures-util = "0.3"

# Memory management
dashmap = "5.5"
parking_lot = "0.12"
once_cell = "1.19"

# Performance monitoring
metrics = "0.23"
metrics-exporter-prometheus = "0.15"

# JSON and validation
validator = { version = "0.18", features = ["derive"] }

# Tensor operations (for host-side work)
ndarray = { version = "0.15", optional = true }

[build-dependencies]
cmake = "0.1"
cc = { version = "1.0", features = ["parallel"] }
bindgen = "0.69"
pkg-config = "0.3"

[dev-dependencies]
tokio-test = { workspace = true }
criterion = { workspace = true }
proptest = { workspace = true }
serial_test = { workspace = true }
reqwest = { workspace = true }
tempfile = "3.8"
rstest = "0.18"

[features]
default = ["cuda"]
cuda = ["cudarc", "candle-core/cuda", "candle-nn", "bindgen", "ndarray"]
cpu-only = ["ndarray"]

# Benchmarks will be added in later phases
# [[bench]]
# name = "latency" 
# harness = false

# [[bench]]
# name = "throughput"
# harness = false